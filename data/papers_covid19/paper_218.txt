1 - Sell Me the Black-box! Regulating Explainable Artificial Intelligence (XAI) May Harm Users Behnam Mohammadi, Carnegie Mellon University, Pittsburgh, PA Kannan Srinivasan, Timothy Derdenger Recent years have seen a surge in the adoption of Artificial Intelligence (AI) models for decision-making in various domains such as targeted advertising, healthcare, and finance. But most recent AI algorithms are complex black- box models whose underlying mechanisms are difficult to understand even by their creators. In life-changing situations such as criminal justice systems and medical diagnosis, however, it is crucial to know the chain of reasoning that leads to certain decisions made by AI. eXplainable AI (XAI) is a set of techniques that seek to address such concerns about AI transparency and trust by making AI outputs understandable to humans. The rapidly growing body of research on XAI coincides with the emerging issue of the regulatory and policy landscape for AI in jurisdictions across the world, such as GDPR in the EU. The common wisdom is that regulating AI and XAI leads to the betterment of society. This paper challenges this notion through a game theoretic analysis of total welfare in a duopoly with and without XAI. The results show that under certain conditions, there is little-to-no additional benefit from mandating XAI. In fact, it follows that XAI policies that require full explainability may actually make both firms and customers worse off, demonstrating a trade- off between maximizing welfare and receiving explainable AI outputs. We identify the factors that must be considered when designing XAI policies, and provide the managerial implications of our results for businesses. 
4 - Comparing Automated Image Classification Methods Keno Tetzlaff, University of Hamburg, Hamburg, Germany Jochen Hartmann, Mark Heitmann The relevance of visual content for marketing research and practice is rapidly increasing. However, the plethora and novelty of methods (both open-source and proprietary black-box methods) makes it challenging for researchers to understand how these perform for actual research  applications. This research intends to guide researchers in choosing the best image classification method. We conduct more than 3,000 experiments using 30 datasets with different application contexts and compare all convolutional neural network architecture families on Keras. Mean method performance varies between 37.0% and 58.2% accuracy suggesting performance depends on both method choice and application context. We conduct multiple regression analyses with accuracy as the dependent variable and method, training hyperparameters as well as dataset characteristics and image pre-processing as independent variables, to investigate the reasons for these differences. Among individual architectures, VGG-16, which is popular in marketing research, performs significantly worse than EfficientNetB0 (+5pp, p<.001) or DenseNet121 (+4pp, p<0.05). Our results suggest marketing researchers can benefit from fine-tuning (+3pp, p<.001) and should consider a pre-selected set of as little as three candidate models to achieve top performance on >90% of our datasets.We also evaluate commercial black-box solutions and find they do not generate a systematic advantage in terms of classification accuracy. In most cases open-source software performs similarly or better, suggesting researchers will rarely have to rely on commercial software. Friday, 11:30amâ€“12:30pm 
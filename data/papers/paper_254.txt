1 - Algorithmic Pricing and Adaptive Bias: Evidence from Insurance Industry Ozge Demirci, University of Warwick, London, United Kingdom Firms today use algorithmic pricing to set prices in an automated way. Insurance companies also use pricing algorithms to offer quotes which are usually different for men and women. As male and female drivers differ in their accident and claim statistics, pricing algorithms use this as a reason for gender-based pricing. Although this can be efficient for firms to differentiate between risk groups, it is also statistical discrimination to take someoneâ€™s group belonging into account while pricing them. This paper focuses on the recent policy change in California requiring gender-neutral pricing in auto insurance. By exploiting the variation across states and using a difference-in-differences method, I show that the insurance price gap between male and female drivers decreased by 6 percentage points after the policy. It reduced premiums for young males, the riskiest group, but they increased for young females, as companies cannot differentiate between these two groups now. Leveraging different machine learning methods, including penalized regressions and random forest, I estimate consumer features that predict gender. By extracting data from thousands of insurance filings, I construct a unique dataset that captures pricing algorithms for different insurance providers. I show that insurance pricing algorithms start to proxy gender with other information already collected by firms. Hence, these characteristics correlated with gender gain more weight in the pricing algorithm. Drivers using specific car models associated with young males, the riskiest group, end up paying up to 20 percent more irrespective of their gender and driving records. It is an example of how well-intended regulatory policies can adapt discrimination in other forms rather than eliminating thoroughly. This paper aims to contribute to the growing literature investigating how algorithmic pricing may perpetuate the bias embedded in previous customer data, even though the anti-discrimination policies aim to achieve more equity.  
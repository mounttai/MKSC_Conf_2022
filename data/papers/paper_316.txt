1 - Competing Ad Targeting Policies using Reinforcement Learning Poet Larsen, Marshall School of Business, Los Angeles, CA Reinforcement Learning algorithms-more specifically multi- armed bandit (MAB) algorithms-are becoming increasingly popular methods used by firms to learn targeted advertising policies. However, little is known about the behavior of these algorithms when competing in advertising settings. In this paper, we ask the following question: Can independent competing targeted marketing strategies, operationalized using MAB algorithms, implicitly learn to segment markets with only consumer response data? We investigate this question with a reduced-form model of advertising and a set of simulations that suggest competing MAB algorithms can independently learn coordinated market segmentation policies without communication, public monitoring, or explicitly accounting for competition. Additionally, we find evidence that suggests market segmentation outcomes  may be driven by randomness, i.e., early draws from the reward distribution impact how the market is sliced. Finally, we explore several market factors that meaningfully impact market segmentation behavior. Our results help marketing academics and practitioners better understand how MAB algorithms behave in competitive advertising settings. 